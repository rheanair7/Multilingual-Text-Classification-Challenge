{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21B1mk1uSgqx",
    "outputId": "bc279613-af40-4d83-8cf2-6d9567ac56d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Archive:  /content/drive/MyDrive/dev_phase.zip\n",
      "   creating: subtask1/\n",
      "   creating: subtask1/dev/\n",
      "  inflating: subtask1/dev/nep.csv    \n",
      "  inflating: subtask1/dev/ita.csv    \n",
      "  inflating: subtask1/dev/hin.csv    \n",
      "  inflating: subtask1/dev/hau.csv    \n",
      "  inflating: subtask1/dev/spa.csv    \n",
      "  inflating: subtask1/dev/deu.csv    \n",
      "  inflating: subtask1/dev/fas.csv    \n",
      "  inflating: subtask1/dev/arb.csv    \n",
      "  inflating: subtask1/dev/amh.csv    \n",
      "  inflating: subtask1/dev/tur.csv    \n",
      "  inflating: subtask1/dev/zho.csv    \n",
      "  inflating: subtask1/dev/eng.csv    \n",
      "  inflating: subtask1/dev/urd.csv    \n",
      "   creating: subtask1/train/\n",
      "  inflating: subtask1/train/nep.csv  \n",
      "  inflating: subtask1/train/ita.csv  \n",
      "  inflating: subtask1/train/hin.csv  \n",
      "  inflating: subtask1/train/fas.csv  \n",
      "  inflating: subtask1/train/deu.csv  \n",
      "  inflating: subtask1/train/hau.csv  \n",
      "  inflating: subtask1/train/spa.csv  \n",
      "  inflating: subtask1/train/arb.csv  \n",
      "  inflating: subtask1/train/tur.csv  \n",
      "  inflating: subtask1/train/zho.csv  \n",
      "  inflating: subtask1/train/amh.csv  \n",
      "  inflating: subtask1/train/urd.csv  \n",
      "  inflating: subtask1/train/eng.csv  \n",
      "   creating: subtask2/\n",
      "   creating: subtask2/train/\n",
      "  inflating: subtask2/train/nep.csv  \n",
      "  inflating: subtask2/train/ita.csv  \n",
      "  inflating: subtask2/train/hin.csv  \n",
      "  inflating: subtask2/train/deu.csv  \n",
      "  inflating: subtask2/train/fas.csv  \n",
      "  inflating: subtask2/train/hau.csv  \n",
      "  inflating: subtask2/train/spa.csv  \n",
      "  inflating: subtask2/train/arb.csv  \n",
      "  inflating: subtask2/train/amh.csv  \n",
      "  inflating: subtask2/train/zho.csv  \n",
      "  inflating: subtask2/train/tur.csv  \n",
      "  inflating: subtask2/train/urd.csv  \n",
      "  inflating: subtask2/train/eng.csv  \n",
      "   creating: subtask2/dev/\n",
      "  inflating: subtask2/dev/ita.csv    \n",
      "  inflating: subtask2/dev/nep.csv    \n",
      "  inflating: subtask2/dev/fas.csv    \n",
      "  inflating: subtask2/dev/deu.csv    \n",
      "  inflating: subtask2/dev/spa.csv    \n",
      "  inflating: subtask2/dev/hau.csv    \n",
      "  inflating: subtask2/dev/hin.csv    \n",
      "  inflating: subtask2/dev/tur.csv    \n",
      "  inflating: subtask2/dev/zho.csv    \n",
      "  inflating: subtask2/dev/amh.csv    \n",
      "  inflating: subtask2/dev/arb.csv    \n",
      "  inflating: subtask2/dev/urd.csv    \n",
      "  inflating: subtask2/dev/eng.csv    \n",
      "   creating: subtask3/\n",
      "   creating: subtask3/dev/\n",
      "  inflating: subtask3/dev/eng.csv    \n",
      "  inflating: subtask3/dev/urd.csv    \n",
      "  inflating: subtask3/dev/arb.csv    \n",
      "  inflating: subtask3/dev/amh.csv    \n",
      "  inflating: subtask3/dev/tur.csv    \n",
      "  inflating: subtask3/dev/zho.csv    \n",
      "  inflating: subtask3/dev/hin.csv    \n",
      "  inflating: subtask3/dev/spa.csv    \n",
      "  inflating: subtask3/dev/hau.csv    \n",
      "  inflating: subtask3/dev/deu.csv    \n",
      "  inflating: subtask3/dev/fas.csv    \n",
      "  inflating: subtask3/dev/nep.csv    \n",
      "   creating: subtask3/train/\n",
      "  inflating: subtask3/train/amh.csv  \n",
      "  inflating: subtask3/train/zho.csv  \n",
      "  inflating: subtask3/train/tur.csv  \n",
      "  inflating: subtask3/train/arb.csv  \n",
      "  inflating: subtask3/train/urd.csv  \n",
      "  inflating: subtask3/train/eng.csv  \n",
      "  inflating: subtask3/train/nep.csv  \n",
      "  inflating: subtask3/train/deu.csv  \n",
      "  inflating: subtask3/train/fas.csv  \n",
      "  inflating: subtask3/train/hau.csv  \n",
      "  inflating: subtask3/train/spa.csv  \n",
      "  inflating: subtask3/train/hin.csv  \n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!unzip /content/drive/MyDrive/dev_phase.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "vlqOJDn8SqWG",
    "outputId": "b01dd5ce-8a1c-4ff9-a5cc-3109546e2b3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/wozuk3b2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7eb0fc7d50d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Disable wandb logging for this script\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD1yg5hZVl4h"
   },
   "source": [
    "LEARNING RATE :2e-5 , EPOCH : 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1614185f75c741e8b542653a00df8918",
      "7b78b468dbbf4d8387c39a12202851f5",
      "bf10726c8110417eb1ff3dbc475b46c8",
      "add844643ddb4474a99f801ea983db59",
      "a5c011c3b13d41d1984d7b21e6b7241e",
      "7cf87eadefca4dae804c838800230e85",
      "9a749877cfb94eb8bfc51b6fd54fa349",
      "c19baa8401044204a6a09519e3124541",
      "51472691a75f48f6a6c21a35f1f22cbc",
      "cc7e31e7c47f4f21b31a5fb677e50928",
      "5dc3ed1e0a7f472093683bc36ac9b770",
      "757b334521024cf9b3aa3da809011259",
      "b529a3b571964df1b863be72c423b3a0",
      "3a5cd468d01d4d80a655d8a107017bad",
      "6a0306b070db400795d6543198f6800b",
      "00492df964e049bab067d018ebd56adc",
      "b1cc8a283eaf4bfab59154d84a99b514",
      "8b6e7992d5984d4c945f2fa8a2ff95bc",
      "3f10d7193f5741ae99f5f27b294c099e",
      "203c8be43bfb4a60b9cdb35c5d6db417",
      "a454aae3f39b4a7fa9c1f072d5780827",
      "9afe2c3474f24c0db4b6cd85cfe78dd9",
      "073e95e848914f7c9ceaabe00cc41128",
      "be90b835f97c4e23a4effb15e4a0083b",
      "d649e316c39b4c828f1b00a6473832df",
      "ca0c868ed4ef4029b08240b1b2823269",
      "7f08472ccf334c6688dacaf94c48accf",
      "22e2a6eb477a48c48d3d5db49c5b56eb",
      "9b9377807a8b47f8a5b8ab40ac3c648d",
      "dfb1f6e01c9d4d9a966a8f4cebfbed2a",
      "d6843b1189fd41bfa05ebc0732275f6c",
      "e3c93164438648718aa9ac54e3e12ed6",
      "54910b8122f44834baea2a677f41112c",
      "559825d487bc45768a096437b76ad3b6",
      "d734f33ecace48b581410fca9f10ee26",
      "e77cdc8a84d741f2ac639dd87eb71f83",
      "6fd9a522c6b7475d9ec91d2f3fec461b",
      "6fc2d5f1fa674a0cbad03f3f073a2207",
      "93d738a4fd5641408b37eb624c18504c",
      "be6c00d7c6d045af889be8e18843a7c7",
      "6c2afd4186814e03bd079e2fd586b317",
      "2988af255f4b47c58ed8f252ee142881",
      "7cd756f537534507a725effa96fa24c5",
      "eff2605ef0f74f88ad15c723e32b3c4c",
      "cf87da7a1938406d9a874b49ee974d31",
      "f1fef065589f4476b6dc4fcc4b841ec5",
      "52e8370fd65a47eabead28a3eb7ad95e",
      "773846333dcd4c4291dfafcdbc031ec1",
      "01ac45f67ed4402198010ab10100f406",
      "420e28b100124dcfb28ddd6b92726835",
      "3f38c41b8de54bc1a157d5e2426d916b",
      "23d91a6e4e354c80b2df74e671f54bf8",
      "240ceb679ef5488384efa43d0282106d",
      "68aaefc2ed1646eebad344961042cf7c",
      "1bbea62722434cb893a1ee1c6c1fce14"
     ]
    },
    "id": "ASO7p5d1SVfU",
    "outputId": "c8d13898-10a2-4930-9822-58562fd46156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1614185f75c741e8b542653a00df8918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757b334521024cf9b3aa3da809011259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073e95e848914f7c9ceaabe00cc41128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      " LANGUAGE: eng\n",
      "Train size: 2140,  Validation size: 536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559825d487bc45768a096437b76ad3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf87da7a1938406d9a874b49ee974d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.631100</td>\n",
       "      <td>0.525668</td>\n",
       "      <td>0.702075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485400</td>\n",
       "      <td>0.484988</td>\n",
       "      <td>0.772796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.466146</td>\n",
       "      <td>0.787869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.465547</td>\n",
       "      <td>0.785753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.460577</td>\n",
       "      <td>0.788822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eng Validation F1 = 0.7888\n",
      " Predicting for dev set (133 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: hin\n",
      "Train size: 2195,  Validation size: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/175 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.373643</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.326982</td>\n",
       "      <td>0.701720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.736722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.312341</td>\n",
       "      <td>0.765440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.202700</td>\n",
       "      <td>0.314117</td>\n",
       "      <td>0.756033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hin Validation F1 = 0.7560\n",
      " Predicting for dev set (137 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: spa\n",
      "Train size: 2644,  Validation size: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 01:31, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.677400</td>\n",
       "      <td>0.624180</td>\n",
       "      <td>0.685928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.570306</td>\n",
       "      <td>0.716923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.557844</td>\n",
       "      <td>0.722878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.571750</td>\n",
       "      <td>0.730556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.582611</td>\n",
       "      <td>0.726920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spa Validation F1 = 0.7269\n",
      " Predicting for dev set (165 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: urd\n",
      "Train size: 2279,  Validation size: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.662200</td>\n",
       "      <td>0.540939</td>\n",
       "      <td>0.694901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>0.488820</td>\n",
       "      <td>0.730283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.510893</td>\n",
       "      <td>0.733649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.589515</td>\n",
       "      <td>0.696984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.359800</td>\n",
       "      <td>0.572799</td>\n",
       "      <td>0.704494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urd Validation F1 = 0.7045\n",
      " Predicting for dev set (142 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: zho\n",
      "Train size: 3424,  Validation size: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.484117</td>\n",
       "      <td>0.803477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.374500</td>\n",
       "      <td>0.371960</td>\n",
       "      <td>0.848128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.368779</td>\n",
       "      <td>0.856238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.381828</td>\n",
       "      <td>0.858622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.385785</td>\n",
       "      <td>0.858504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " zho Validation F1 = 0.8585\n",
      " Predicting for dev set (214 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: arb\n",
      "Train size: 2704,  Validation size: 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 01:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>0.514282</td>\n",
       "      <td>0.737506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.479710</td>\n",
       "      <td>0.773128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.337800</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>0.767197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.286400</td>\n",
       "      <td>0.518066</td>\n",
       "      <td>0.768954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.542999</td>\n",
       "      <td>0.768262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " arb Validation F1 = 0.7683\n",
      " Predicting for dev set (169 rows)...\n",
      " Saved: eng_dev_predicted.csv\n",
      " Saved: hin_dev_predicted.csv\n",
      " Saved: spa_dev_predicted.csv\n",
      " Saved: urd_dev_predicted.csv\n",
      " Saved: zho_dev_predicted.csv\n",
      " Saved: arb_dev_predicted.csv\n",
      "\n",
      " FINAL F1 SCORES:\n",
      "  language  f1_macro\n",
      "0      eng  0.788822\n",
      "1      hin  0.756033\n",
      "2      spa  0.726920\n",
      "3      urd  0.704494\n",
      "4      zho  0.858504\n",
      "5      arb  0.768262\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive.mount('/content/drive')\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ---------------------------------------\n",
    "# Dataset class\n",
    "# ---------------------------------------\n",
    "class PolarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, require_labels=True):\n",
    "        self.texts = df[\"text\"].fillna(\"\").tolist()\n",
    "        if require_labels:\n",
    "            self.labels = df[\"polarization\"].astype(int).tolist()\n",
    "        else:\n",
    "            self.labels = [0] * len(self.texts)  # dummy labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------\n",
    "languages = [\"eng\",\"hin\",\"spa\",\"urd\",\"zho\",\"arb\"]\n",
    "data = {}\n",
    "\n",
    "for lang in languages:\n",
    "    train_df = pd.read_csv(f\"subtask1/train/{lang}.csv\")   # labeled\n",
    "    dev_df   = pd.read_csv(f\"subtask1/dev/{lang}.csv\")     # unlabeled\n",
    "    data[lang] = {\"train\": train_df, \"dev\": dev_df}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Metric\n",
    "# ---------------------------------------\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"f1_macro\": f1_score(p.label_ids, preds, average=\"macro\")}\n",
    "\n",
    "# ---------------------------------------\n",
    "# MAIN LOOP: TRAIN/VAL SPLIT + DEV PREDICTION\n",
    "# ---------------------------------------\n",
    "f1_results = []\n",
    "predicted_outputs = {}\n",
    "\n",
    "for lang, dfs in data.items():\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\" LANGUAGE: {lang}\")\n",
    "\n",
    "    train_df = dfs[\"train\"]\n",
    "    dev_df   = dfs[\"dev\"]\n",
    "\n",
    "    # 1️⃣ Filter ONLY labeled training rows\n",
    "    train_labeled = train_df.dropna(subset=[\"polarization\"]).reset_index(drop=True)\n",
    "\n",
    "    # 2️⃣ Split train into train/validation\n",
    "    train_split, val_split = train_test_split(\n",
    "        train_labeled,\n",
    "        test_size=0.20,\n",
    "        stratify=train_labeled[\"polarization\"],\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_split)},  Validation size: {len(val_split)}\")\n",
    "\n",
    "    train_dataset = PolarizationDataset(train_split, tokenizer, require_labels=True)\n",
    "    val_dataset   = PolarizationDataset(val_split,   tokenizer, require_labels=True)\n",
    "\n",
    "    # 3️⃣ Train model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"microsoft/mdeberta-v3-base\", num_labels=2\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./model_{lang}\",\n",
    "        learning_rate=2e-5,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=16,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=20\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 4️⃣ Compute F1 on validation\n",
    "    metrics = trainer.evaluate()\n",
    "    f1 = metrics[\"eval_f1_macro\"]\n",
    "    print(f\" {lang} Validation F1 = {f1:.4f}\")\n",
    "\n",
    "    f1_results.append({\"language\": lang, \"f1_macro\": f1})\n",
    "\n",
    "    # 5️⃣ Predict on dev (UNLABELED)\n",
    "    print(f\" Predicting for dev set ({len(dev_df)} rows)...\")\n",
    "    dev_dataset = PolarizationDataset(dev_df, tokenizer, require_labels=False)\n",
    "    preds = trainer.predict(dev_dataset)\n",
    "    pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "    dev_df[\"predicted_polarization\"] = pred_labels\n",
    "    predicted_outputs[lang] = dev_df\n",
    "\n",
    "# ---------------------------------------\n",
    "# SAVE PREDICTIONS\n",
    "# ---------------------------------------\n",
    "for lang, df_pred in predicted_outputs.items():\n",
    "    df_pred.to_csv(f\"{lang}_dev_predicted.csv\", index=False)\n",
    "    print(f\" Saved: {lang}_dev_predicted.csv\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# FINAL F1 SCORES\n",
    "# ---------------------------------------\n",
    "f1_df = pd.DataFrame(f1_results)\n",
    "print(\"\\n FINAL F1 SCORES:\")\n",
    "print(f1_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6czcXNSgZEBm"
   },
   "source": [
    "LEARNING RATE: 1e-5 EPOCH:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qfE9IyDMVYDa",
    "outputId": "fd8ed226-28ba-4e88-ee00-2e660a84d146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      " LANGUAGE: eng\n",
      "Train size: 2140,  Validation size: 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.550940</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.524046</td>\n",
       "      <td>0.495097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.479700</td>\n",
       "      <td>0.510029</td>\n",
       "      <td>0.764222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.490972</td>\n",
       "      <td>0.790876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.491663</td>\n",
       "      <td>0.791830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eng Validation F1 = 0.7918\n",
      " Predicting for dev set (133 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: hin\n",
      "Train size: 2195,  Validation size: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/175 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.403355</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.360659</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.320147</td>\n",
       "      <td>0.614930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289200</td>\n",
       "      <td>0.299303</td>\n",
       "      <td>0.720788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.285100</td>\n",
       "      <td>0.302403</td>\n",
       "      <td>0.724999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hin Validation F1 = 0.7250\n",
      " Predicting for dev set (137 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: spa\n",
      "Train size: 2644,  Validation size: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 01:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.679334</td>\n",
       "      <td>0.519762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.621200</td>\n",
       "      <td>0.615305</td>\n",
       "      <td>0.692662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.555600</td>\n",
       "      <td>0.584920</td>\n",
       "      <td>0.700010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.539500</td>\n",
       "      <td>0.579606</td>\n",
       "      <td>0.713172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.524500</td>\n",
       "      <td>0.576889</td>\n",
       "      <td>0.706230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spa Validation F1 = 0.7062\n",
      " Predicting for dev set (165 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: urd\n",
      "Train size: 2279,  Validation size: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.595619</td>\n",
       "      <td>0.409326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.516469</td>\n",
       "      <td>0.723111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.499800</td>\n",
       "      <td>0.492263</td>\n",
       "      <td>0.730867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.499344</td>\n",
       "      <td>0.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.498980</td>\n",
       "      <td>0.721408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urd Validation F1 = 0.7214\n",
      " Predicting for dev set (142 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: zho\n",
      "Train size: 3424,  Validation size: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.671300</td>\n",
       "      <td>0.549092</td>\n",
       "      <td>0.748882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.438433</td>\n",
       "      <td>0.825881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358300</td>\n",
       "      <td>0.406347</td>\n",
       "      <td>0.829625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.402044</td>\n",
       "      <td>0.832995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.294400</td>\n",
       "      <td>0.401512</td>\n",
       "      <td>0.835746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " zho Validation F1 = 0.8357\n",
      " Predicting for dev set (214 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: arb\n",
      "Train size: 2704,  Validation size: 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 01:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.582900</td>\n",
       "      <td>0.538088</td>\n",
       "      <td>0.724560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.474885</td>\n",
       "      <td>0.770669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.486779</td>\n",
       "      <td>0.759612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.472108</td>\n",
       "      <td>0.779956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.483933</td>\n",
       "      <td>0.768296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " arb Validation F1 = 0.7683\n",
      " Predicting for dev set (169 rows)...\n",
      " Saved: eng_dev_predicted.csv\n",
      " Saved: hin_dev_predicted.csv\n",
      " Saved: spa_dev_predicted.csv\n",
      " Saved: urd_dev_predicted.csv\n",
      " Saved: zho_dev_predicted.csv\n",
      " Saved: arb_dev_predicted.csv\n",
      "\n",
      " FINAL F1 SCORES:\n",
      "  language  f1_macro\n",
      "0      eng  0.791830\n",
      "1      hin  0.724999\n",
      "2      spa  0.706230\n",
      "3      urd  0.721408\n",
      "4      zho  0.835746\n",
      "5      arb  0.768296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive.mount('/content/drive')\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ---------------------------------------\n",
    "# Dataset class\n",
    "# ---------------------------------------\n",
    "class PolarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, require_labels=True):\n",
    "        self.texts = df[\"text\"].fillna(\"\").tolist()\n",
    "        if require_labels:\n",
    "            self.labels = df[\"polarization\"].astype(int).tolist()\n",
    "        else:\n",
    "            self.labels = [0] * len(self.texts)  # dummy labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------\n",
    "languages = [\"eng\",\"hin\",\"spa\",\"urd\",\"zho\",\"arb\"]\n",
    "data = {}\n",
    "\n",
    "for lang in languages:\n",
    "    train_df = pd.read_csv(f\"subtask1/train/{lang}.csv\")   # labeled\n",
    "    dev_df   = pd.read_csv(f\"subtask1/dev/{lang}.csv\")     # unlabeled\n",
    "    data[lang] = {\"train\": train_df, \"dev\": dev_df}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Metric\n",
    "# ---------------------------------------\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"f1_macro\": f1_score(p.label_ids, preds, average=\"macro\")}\n",
    "\n",
    "# ---------------------------------------\n",
    "# MAIN LOOP: TRAIN/VAL SPLIT + DEV PREDICTION\n",
    "# ---------------------------------------\n",
    "f1_results = []\n",
    "predicted_outputs = {}\n",
    "\n",
    "for lang, dfs in data.items():\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\" LANGUAGE: {lang}\")\n",
    "\n",
    "    train_df = dfs[\"train\"]\n",
    "    dev_df   = dfs[\"dev\"]\n",
    "\n",
    "    # 1️⃣ Filter ONLY labeled training rows\n",
    "    train_labeled = train_df.dropna(subset=[\"polarization\"]).reset_index(drop=True)\n",
    "\n",
    "    # 2️⃣ Split train into train/validation\n",
    "    train_split, val_split = train_test_split(\n",
    "        train_labeled,\n",
    "        test_size=0.20,\n",
    "        stratify=train_labeled[\"polarization\"],\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_split)},  Validation size: {len(val_split)}\")\n",
    "\n",
    "    train_dataset = PolarizationDataset(train_split, tokenizer, require_labels=True)\n",
    "    val_dataset   = PolarizationDataset(val_split,   tokenizer, require_labels=True)\n",
    "\n",
    "    # 3️⃣ Train model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"microsoft/mdeberta-v3-base\", num_labels=2\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./model_{lang}\",\n",
    "        learning_rate=1e-5,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=16,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=20\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 4️⃣ Compute F1 on validation\n",
    "    metrics = trainer.evaluate()\n",
    "    f1 = metrics[\"eval_f1_macro\"]\n",
    "    print(f\" {lang} Validation F1 = {f1:.4f}\")\n",
    "\n",
    "    f1_results.append({\"language\": lang, \"f1_macro\": f1})\n",
    "\n",
    "    # 5️⃣ Predict on dev (UNLABELED)\n",
    "    print(f\" Predicting for dev set ({len(dev_df)} rows)...\")\n",
    "    dev_dataset = PolarizationDataset(dev_df, tokenizer, require_labels=False)\n",
    "    preds = trainer.predict(dev_dataset)\n",
    "    pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "    dev_df[\"predicted_polarization\"] = pred_labels\n",
    "    predicted_outputs[lang] = dev_df\n",
    "\n",
    "# ---------------------------------------\n",
    "# SAVE PREDICTIONS\n",
    "# ---------------------------------------\n",
    "for lang, df_pred in predicted_outputs.items():\n",
    "    df_pred.to_csv(f\"{lang}_dev_predicted.csv\", index=False)\n",
    "    print(f\" Saved: {lang}_dev_predicted.csv\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# FINAL F1 SCORES\n",
    "# ---------------------------------------\n",
    "f1_df = pd.DataFrame(f1_results)\n",
    "print(\"\\n FINAL F1 SCORES:\")\n",
    "print(f1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yR_WAaXbW1Ej",
    "outputId": "bbe08f9d-39f6-4db1-d1b1-760e6b87a249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      " LANGUAGE: eng\n",
      "Train size: 2140,  Validation size: 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 02:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.649300</td>\n",
       "      <td>0.548584</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>0.519991</td>\n",
       "      <td>0.752472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.465300</td>\n",
       "      <td>0.512483</td>\n",
       "      <td>0.765174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.476034</td>\n",
       "      <td>0.771526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.507187</td>\n",
       "      <td>0.777858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.350200</td>\n",
       "      <td>0.496946</td>\n",
       "      <td>0.787183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.788201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.788201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.285400</td>\n",
       "      <td>0.507672</td>\n",
       "      <td>0.792088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.263800</td>\n",
       "      <td>0.513283</td>\n",
       "      <td>0.783977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eng Validation F1 = 0.7840\n",
      " Predicting for dev set (133 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: hin\n",
      "Train size: 2195,  Validation size: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 02:37, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.531600</td>\n",
       "      <td>0.404365</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.386658</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.331400</td>\n",
       "      <td>0.343277</td>\n",
       "      <td>0.646393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.331015</td>\n",
       "      <td>0.642757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.307892</td>\n",
       "      <td>0.710624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>0.308145</td>\n",
       "      <td>0.753190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.308011</td>\n",
       "      <td>0.737468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.313227</td>\n",
       "      <td>0.743592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.186800</td>\n",
       "      <td>0.314294</td>\n",
       "      <td>0.741247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.316457</td>\n",
       "      <td>0.737468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hin Validation F1 = 0.7375\n",
      " Predicting for dev set (137 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: spa\n",
      "Train size: 2644,  Validation size: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [420/420 03:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.687047</td>\n",
       "      <td>0.644224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.564916</td>\n",
       "      <td>0.715596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.506300</td>\n",
       "      <td>0.550599</td>\n",
       "      <td>0.727230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.463400</td>\n",
       "      <td>0.556177</td>\n",
       "      <td>0.750321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.560209</td>\n",
       "      <td>0.754912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.341400</td>\n",
       "      <td>0.637651</td>\n",
       "      <td>0.737698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.618278</td>\n",
       "      <td>0.742681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.654075</td>\n",
       "      <td>0.739057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.644911</td>\n",
       "      <td>0.745629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.270200</td>\n",
       "      <td>0.660517</td>\n",
       "      <td>0.740693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spa Validation F1 = 0.7407\n",
      " Predicting for dev set (165 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: urd\n",
      "Train size: 2279,  Validation size: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 02:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.585910</td>\n",
       "      <td>0.409326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542600</td>\n",
       "      <td>0.510875</td>\n",
       "      <td>0.698058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.466600</td>\n",
       "      <td>0.533393</td>\n",
       "      <td>0.711149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.404100</td>\n",
       "      <td>0.528062</td>\n",
       "      <td>0.709800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.596112</td>\n",
       "      <td>0.692792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.588718</td>\n",
       "      <td>0.700725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.278600</td>\n",
       "      <td>0.628294</td>\n",
       "      <td>0.700226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.274700</td>\n",
       "      <td>0.598247</td>\n",
       "      <td>0.712454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>0.639238</td>\n",
       "      <td>0.710293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.655661</td>\n",
       "      <td>0.707146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urd Validation F1 = 0.7071\n",
      " Predicting for dev set (142 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: zho\n",
      "Train size: 3424,  Validation size: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>0.523766</td>\n",
       "      <td>0.772496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.428475</td>\n",
       "      <td>0.830579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.367117</td>\n",
       "      <td>0.850460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.312900</td>\n",
       "      <td>0.367456</td>\n",
       "      <td>0.850721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.375407</td>\n",
       "      <td>0.859787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.207700</td>\n",
       "      <td>0.382524</td>\n",
       "      <td>0.859847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.197700</td>\n",
       "      <td>0.373274</td>\n",
       "      <td>0.868711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>0.381128</td>\n",
       "      <td>0.866290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.392941</td>\n",
       "      <td>0.869101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.392194</td>\n",
       "      <td>0.867817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " zho Validation F1 = 0.8678\n",
      " Predicting for dev set (214 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: arb\n",
      "Train size: 2704,  Validation size: 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [430/430 03:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.573268</td>\n",
       "      <td>0.690748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.472267</td>\n",
       "      <td>0.770227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.383900</td>\n",
       "      <td>0.478639</td>\n",
       "      <td>0.776603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.489504</td>\n",
       "      <td>0.789676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.513855</td>\n",
       "      <td>0.771557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.526995</td>\n",
       "      <td>0.771389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.582942</td>\n",
       "      <td>0.761664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>0.570255</td>\n",
       "      <td>0.776886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.585845</td>\n",
       "      <td>0.778605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.596242</td>\n",
       "      <td>0.776681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " arb Validation F1 = 0.7767\n",
      " Predicting for dev set (169 rows)...\n",
      " Saved: eng_dev_predicted.csv\n",
      " Saved: hin_dev_predicted.csv\n",
      " Saved: spa_dev_predicted.csv\n",
      " Saved: urd_dev_predicted.csv\n",
      " Saved: zho_dev_predicted.csv\n",
      " Saved: arb_dev_predicted.csv\n",
      "\n",
      " FINAL F1 SCORES:\n",
      "  language  f1_macro\n",
      "0      eng  0.783977\n",
      "1      hin  0.737468\n",
      "2      spa  0.740693\n",
      "3      urd  0.707146\n",
      "4      zho  0.867817\n",
      "5      arb  0.776681\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive.mount('/content/drive')\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ---------------------------------------\n",
    "# Dataset class\n",
    "# ---------------------------------------\n",
    "class PolarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, require_labels=True):\n",
    "        self.texts = df[\"text\"].fillna(\"\").tolist()\n",
    "        if require_labels:\n",
    "            self.labels = df[\"polarization\"].astype(int).tolist()\n",
    "        else:\n",
    "            self.labels = [0] * len(self.texts)  # dummy labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------\n",
    "languages = [\"eng\",\"hin\",\"spa\",\"urd\",\"zho\",\"arb\"]\n",
    "data = {}\n",
    "\n",
    "for lang in languages:\n",
    "    train_df = pd.read_csv(f\"subtask1/train/{lang}.csv\")   # labeled\n",
    "    dev_df   = pd.read_csv(f\"subtask1/dev/{lang}.csv\")     # unlabeled\n",
    "    data[lang] = {\"train\": train_df, \"dev\": dev_df}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Metric\n",
    "# ---------------------------------------\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"f1_macro\": f1_score(p.label_ids, preds, average=\"macro\")}\n",
    "\n",
    "# ---------------------------------------\n",
    "# MAIN LOOP: TRAIN/VAL SPLIT + DEV PREDICTION\n",
    "# ---------------------------------------\n",
    "f1_results = []\n",
    "predicted_outputs = {}\n",
    "\n",
    "for lang, dfs in data.items():\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\" LANGUAGE: {lang}\")\n",
    "\n",
    "    train_df = dfs[\"train\"]\n",
    "    dev_df   = dfs[\"dev\"]\n",
    "\n",
    "    # 1️⃣ Filter ONLY labeled training rows\n",
    "    train_labeled = train_df.dropna(subset=[\"polarization\"]).reset_index(drop=True)\n",
    "\n",
    "    # 2️⃣ Split train into train/validation\n",
    "    train_split, val_split = train_test_split(\n",
    "        train_labeled,\n",
    "        test_size=0.20,\n",
    "        stratify=train_labeled[\"polarization\"],\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_split)},  Validation size: {len(val_split)}\")\n",
    "\n",
    "    train_dataset = PolarizationDataset(train_split, tokenizer, require_labels=True)\n",
    "    val_dataset   = PolarizationDataset(val_split,   tokenizer, require_labels=True)\n",
    "\n",
    "    # 3️⃣ Train model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"microsoft/mdeberta-v3-base\", num_labels=2\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./model_{lang}\",\n",
    "        learning_rate=1e-5,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=16,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=20,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 4️⃣ Compute F1 on validation\n",
    "    metrics = trainer.evaluate()\n",
    "    f1 = metrics[\"eval_f1_macro\"]\n",
    "    print(f\" {lang} Validation F1 = {f1:.4f}\")\n",
    "\n",
    "    f1_results.append({\"language\": lang, \"f1_macro\": f1})\n",
    "\n",
    "    # 5️⃣ Predict on dev (UNLABELED)\n",
    "    print(f\" Predicting for dev set ({len(dev_df)} rows)...\")\n",
    "    dev_dataset = PolarizationDataset(dev_df, tokenizer, require_labels=False)\n",
    "    preds = trainer.predict(dev_dataset)\n",
    "    pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "    dev_df[\"predicted_polarization\"] = pred_labels\n",
    "    predicted_outputs[lang] = dev_df\n",
    "\n",
    "# ---------------------------------------\n",
    "# SAVE PREDICTIONS\n",
    "# ---------------------------------------\n",
    "for lang, df_pred in predicted_outputs.items():\n",
    "    df_pred.to_csv(f\"{lang}_dev_predicted.csv\", index=False)\n",
    "    print(f\" Saved: {lang}_dev_predicted.csv\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# FINAL F1 SCORES\n",
    "# ---------------------------------------\n",
    "f1_df = pd.DataFrame(f1_results)\n",
    "print(\"\\n FINAL F1 SCORES:\")\n",
    "print(f1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bKtKKWq3eCQX",
    "outputId": "bb9495f6-80c3-4693-fb6e-43b5c0eef777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      " LANGUAGE: eng\n",
      "Train size: 2140,  Validation size: 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>0.575518</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.520420</td>\n",
       "      <td>0.682765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.475200</td>\n",
       "      <td>0.497338</td>\n",
       "      <td>0.768257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.474629</td>\n",
       "      <td>0.778252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.469080</td>\n",
       "      <td>0.776085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eng Validation F1 = 0.7761\n",
      " Predicting for dev set (133 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: hin\n",
      "Train size: 2195,  Validation size: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [175/175 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.410252</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.358020</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>0.317473</td>\n",
       "      <td>0.674844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.301805</td>\n",
       "      <td>0.735543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>0.300744</td>\n",
       "      <td>0.739867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hin Validation F1 = 0.7399\n",
      " Predicting for dev set (137 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: spa\n",
      "Train size: 2644,  Validation size: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='210' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [210/210 01:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.689585</td>\n",
       "      <td>0.557413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.637600</td>\n",
       "      <td>0.618649</td>\n",
       "      <td>0.689135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.576970</td>\n",
       "      <td>0.688319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.540100</td>\n",
       "      <td>0.572387</td>\n",
       "      <td>0.723698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.517900</td>\n",
       "      <td>0.559405</td>\n",
       "      <td>0.711873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spa Validation F1 = 0.7119\n",
      " Predicting for dev set (165 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: urd\n",
      "Train size: 2279,  Validation size: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [180/180 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.758200</td>\n",
       "      <td>0.581413</td>\n",
       "      <td>0.409326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.538239</td>\n",
       "      <td>0.409326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.526869</td>\n",
       "      <td>0.409326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.476800</td>\n",
       "      <td>0.504108</td>\n",
       "      <td>0.646668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.506018</td>\n",
       "      <td>0.710498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urd Validation F1 = 0.7105\n",
      " Predicting for dev set (142 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: zho\n",
      "Train size: 3424,  Validation size: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 01:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.605140</td>\n",
       "      <td>0.755833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.464657</td>\n",
       "      <td>0.806048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>0.414098</td>\n",
       "      <td>0.829743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.408223</td>\n",
       "      <td>0.835283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.404882</td>\n",
       "      <td>0.838041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " zho Validation F1 = 0.8380\n",
      " Predicting for dev set (214 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: arb\n",
      "Train size: 2704,  Validation size: 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 01:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.609240</td>\n",
       "      <td>0.656416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.477260</td>\n",
       "      <td>0.772171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.485606</td>\n",
       "      <td>0.757449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>0.482987</td>\n",
       "      <td>0.766117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.494079</td>\n",
       "      <td>0.765612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " arb Validation F1 = 0.7656\n",
      " Predicting for dev set (169 rows)...\n",
      " Saved: eng_dev_predicted.csv\n",
      " Saved: hin_dev_predicted.csv\n",
      " Saved: spa_dev_predicted.csv\n",
      " Saved: urd_dev_predicted.csv\n",
      " Saved: zho_dev_predicted.csv\n",
      " Saved: arb_dev_predicted.csv\n",
      "\n",
      " FINAL F1 SCORES:\n",
      "  language  f1_macro\n",
      "0      eng  0.776085\n",
      "1      hin  0.739867\n",
      "2      spa  0.711873\n",
      "3      urd  0.710498\n",
      "4      zho  0.838041\n",
      "5      arb  0.765612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive.mount('/content/drive')\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ---------------------------------------\n",
    "# Dataset class\n",
    "# ---------------------------------------\n",
    "class PolarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, require_labels=True):\n",
    "        self.texts = df[\"text\"].fillna(\"\").tolist()\n",
    "        if require_labels:\n",
    "            self.labels = df[\"polarization\"].astype(int).tolist()\n",
    "        else:\n",
    "            self.labels = [0] * len(self.texts)  # dummy labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------\n",
    "languages = [\"eng\",\"hin\",\"spa\",\"urd\",\"zho\",\"arb\"]\n",
    "data = {}\n",
    "\n",
    "for lang in languages:\n",
    "    train_df = pd.read_csv(f\"subtask1/train/{lang}.csv\")   # labeled\n",
    "    dev_df   = pd.read_csv(f\"subtask1/dev/{lang}.csv\")     # unlabeled\n",
    "    data[lang] = {\"train\": train_df, \"dev\": dev_df}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Metric\n",
    "# ---------------------------------------\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"f1_macro\": f1_score(p.label_ids, preds, average=\"macro\")}\n",
    "\n",
    "# ---------------------------------------\n",
    "# MAIN LOOP: TRAIN/VAL SPLIT + DEV PREDICTION\n",
    "# ---------------------------------------\n",
    "f1_results = []\n",
    "predicted_outputs = {}\n",
    "\n",
    "for lang, dfs in data.items():\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\" LANGUAGE: {lang}\")\n",
    "\n",
    "    train_df = dfs[\"train\"]\n",
    "    dev_df   = dfs[\"dev\"]\n",
    "\n",
    "    # 1️⃣ Filter ONLY labeled training rows\n",
    "    train_labeled = train_df.dropna(subset=[\"polarization\"]).reset_index(drop=True)\n",
    "\n",
    "    # 2️⃣ Split train into train/validation\n",
    "    train_split, val_split = train_test_split(\n",
    "        train_labeled,\n",
    "        test_size=0.20,\n",
    "        stratify=train_labeled[\"polarization\"],\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_split)},  Validation size: {len(val_split)}\")\n",
    "\n",
    "    train_dataset = PolarizationDataset(train_split, tokenizer, require_labels=True)\n",
    "    val_dataset   = PolarizationDataset(val_split,   tokenizer, require_labels=True)\n",
    "\n",
    "    # 3️⃣ Train model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"microsoft/mdeberta-v3-base\", num_labels=2\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir=f\"./model_{lang}\",\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    logging_steps=20,\n",
    "\n",
    "    # added as you requested\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 4️⃣ Compute F1 on validation\n",
    "    metrics = trainer.evaluate()\n",
    "    f1 = metrics[\"eval_f1_macro\"]\n",
    "    print(f\" {lang} Validation F1 = {f1:.4f}\")\n",
    "\n",
    "    f1_results.append({\"language\": lang, \"f1_macro\": f1})\n",
    "\n",
    "    # 5️⃣ Predict on dev (UNLABELED)\n",
    "    print(f\" Predicting for dev set ({len(dev_df)} rows)...\")\n",
    "    dev_dataset = PolarizationDataset(dev_df, tokenizer, require_labels=False)\n",
    "    preds = trainer.predict(dev_dataset)\n",
    "    pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "    dev_df[\"predicted_polarization\"] = pred_labels\n",
    "    predicted_outputs[lang] = dev_df\n",
    "\n",
    "# ---------------------------------------\n",
    "# SAVE PREDICTIONS\n",
    "# ---------------------------------------\n",
    "for lang, df_pred in predicted_outputs.items():\n",
    "    df_pred.to_csv(f\"{lang}_dev_predicted.csv\", index=False)\n",
    "    print(f\" Saved: {lang}_dev_predicted.csv\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# FINAL F1 SCORES\n",
    "# ---------------------------------------\n",
    "f1_df = pd.DataFrame(f1_results)\n",
    "print(\"\\n FINAL F1 SCORES:\")\n",
    "print(f1_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YsRfPOYajQGL",
    "outputId": "d8338a3b-55e6-44d1-a2b2-43eca9279f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================\n",
      " LANGUAGE: eng\n",
      "Train size: 2140,  Validation size: 536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='335' max='335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [335/335 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.583300</td>\n",
       "      <td>0.534133</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.475503</td>\n",
       "      <td>0.774326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.383300</td>\n",
       "      <td>0.519145</td>\n",
       "      <td>0.762127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.464389</td>\n",
       "      <td>0.780857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320500</td>\n",
       "      <td>0.474658</td>\n",
       "      <td>0.783193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " eng Validation F1 = 0.7832\n",
      " Predicting for dev set (133 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: hin\n",
      "Train size: 2195,  Validation size: 549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/345 01:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.389759</td>\n",
       "      <td>0.460707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.305972</td>\n",
       "      <td>0.731442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.302578</td>\n",
       "      <td>0.743138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>0.316570</td>\n",
       "      <td>0.762816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.315392</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hin Validation F1 = 0.7659\n",
      " Predicting for dev set (137 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: spa\n",
      "Train size: 2644,  Validation size: 661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='415' max='415' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [415/415 01:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.643613</td>\n",
       "      <td>0.664312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.581900</td>\n",
       "      <td>0.553948</td>\n",
       "      <td>0.712890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.549940</td>\n",
       "      <td>0.735644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.559146</td>\n",
       "      <td>0.739057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.454500</td>\n",
       "      <td>0.562146</td>\n",
       "      <td>0.739415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spa Validation F1 = 0.7394\n",
      " Predicting for dev set (165 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: urd\n",
      "Train size: 2279,  Validation size: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 01:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>0.547224</td>\n",
       "      <td>0.409326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>0.495450</td>\n",
       "      <td>0.528194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.471344</td>\n",
       "      <td>0.745109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.429500</td>\n",
       "      <td>0.473527</td>\n",
       "      <td>0.737246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.473931</td>\n",
       "      <td>0.741766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urd Validation F1 = 0.7451\n",
      " Predicting for dev set (142 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: zho\n",
      "Train size: 3424,  Validation size: 856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='535' max='535' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [535/535 01:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.458759</td>\n",
       "      <td>0.797950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.392900</td>\n",
       "      <td>0.391890</td>\n",
       "      <td>0.836220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.378026</td>\n",
       "      <td>0.849190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.388466</td>\n",
       "      <td>0.861932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.392325</td>\n",
       "      <td>0.862113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " zho Validation F1 = 0.8621\n",
      " Predicting for dev set (214 rows)...\n",
      "\n",
      "====================================\n",
      " LANGUAGE: arb\n",
      "Train size: 2704,  Validation size: 676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='425' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [425/425 01:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.519200</td>\n",
       "      <td>0.543641</td>\n",
       "      <td>0.701777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.414800</td>\n",
       "      <td>0.466359</td>\n",
       "      <td>0.782544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.479337</td>\n",
       "      <td>0.773594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.521434</td>\n",
       "      <td>0.774456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.280300</td>\n",
       "      <td>0.515198</td>\n",
       "      <td>0.765161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " arb Validation F1 = 0.7825\n",
      " Predicting for dev set (169 rows)...\n",
      " Saved: eng_dev_predicted.csv\n",
      " Saved: hin_dev_predicted.csv\n",
      " Saved: spa_dev_predicted.csv\n",
      " Saved: urd_dev_predicted.csv\n",
      " Saved: zho_dev_predicted.csv\n",
      " Saved: arb_dev_predicted.csv\n",
      "\n",
      " FINAL F1 SCORES:\n",
      "  language  f1_macro\n",
      "0      eng  0.783193\n",
      "1      hin  0.765854\n",
      "2      spa  0.739415\n",
      "3      urd  0.745109\n",
      "4      zho  0.862113\n",
      "5      arb  0.782544\n"
     ]
    }
   ],
   "source": [
    "\n",
    "drive.mount('/content/drive')\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# ---------------------------------------\n",
    "# Dataset class\n",
    "# ---------------------------------------\n",
    "class PolarizationDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, require_labels=True):\n",
    "        self.texts = df[\"text\"].fillna(\"\").tolist()\n",
    "        if require_labels:\n",
    "            self.labels = df[\"polarization\"].astype(int).tolist()\n",
    "        else:\n",
    "            self.labels = [0] * len(self.texts)  # dummy labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=256,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k,v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "# ---------------------------------------\n",
    "# Load data\n",
    "# ---------------------------------------\n",
    "languages = [\"eng\",\"hin\",\"spa\",\"urd\",\"zho\",\"arb\"]\n",
    "data = {}\n",
    "\n",
    "for lang in languages:\n",
    "    train_df = pd.read_csv(f\"subtask1/train/{lang}.csv\")   # labeled\n",
    "    dev_df   = pd.read_csv(f\"subtask1/dev/{lang}.csv\")     # unlabeled\n",
    "    data[lang] = {\"train\": train_df, \"dev\": dev_df}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/mdeberta-v3-base\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# Metric\n",
    "# ---------------------------------------\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"f1_macro\": f1_score(p.label_ids, preds, average=\"macro\")}\n",
    "\n",
    "# ---------------------------------------\n",
    "# MAIN LOOP: TRAIN/VAL SPLIT + DEV PREDICTION\n",
    "# ---------------------------------------\n",
    "f1_results = []\n",
    "predicted_outputs = {}\n",
    "\n",
    "for lang, dfs in data.items():\n",
    "    print(\"\\n====================================\")\n",
    "    print(f\" LANGUAGE: {lang}\")\n",
    "\n",
    "    train_df = dfs[\"train\"]\n",
    "    dev_df   = dfs[\"dev\"]\n",
    "\n",
    "    # 1️⃣ Filter ONLY labeled training rows\n",
    "    train_labeled = train_df.dropna(subset=[\"polarization\"]).reset_index(drop=True)\n",
    "\n",
    "    # 2️⃣ Split train into train/validation\n",
    "    train_split, val_split = train_test_split(\n",
    "        train_labeled,\n",
    "        test_size=0.20,\n",
    "        stratify=train_labeled[\"polarization\"],\n",
    "        random_state=42,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(f\"Train size: {len(train_split)},  Validation size: {len(val_split)}\")\n",
    "\n",
    "    train_dataset = PolarizationDataset(train_split, tokenizer, require_labels=True)\n",
    "    val_dataset   = PolarizationDataset(val_split,   tokenizer, require_labels=True)\n",
    "\n",
    "    # 3️⃣ Train model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"microsoft/mdeberta-v3-base\", num_labels=2\n",
    "    )\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir=f\"./model_{lang}\",\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    fp16=True,\n",
    "    max_grad_norm=1.0,\n",
    "\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=20,\n",
    ")\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 4️⃣ Compute F1 on validation\n",
    "    metrics = trainer.evaluate()\n",
    "    f1 = metrics[\"eval_f1_macro\"]\n",
    "    print(f\" {lang} Validation F1 = {f1:.4f}\")\n",
    "\n",
    "    f1_results.append({\"language\": lang, \"f1_macro\": f1})\n",
    "\n",
    "    # 5️⃣ Predict on dev (UNLABELED)\n",
    "    print(f\" Predicting for dev set ({len(dev_df)} rows)...\")\n",
    "    dev_dataset = PolarizationDataset(dev_df, tokenizer, require_labels=False)\n",
    "    preds = trainer.predict(dev_dataset)\n",
    "    pred_labels = np.argmax(preds.predictions, axis=1)\n",
    "\n",
    "    dev_df[\"predicted_polarization\"] = pred_labels\n",
    "    predicted_outputs[lang] = dev_df\n",
    "\n",
    "# ---------------------------------------\n",
    "# SAVE PREDICTIONS\n",
    "# ---------------------------------------\n",
    "for lang, df_pred in predicted_outputs.items():\n",
    "    df_pred.to_csv(f\"{lang}_dev_predicted.csv\", index=False)\n",
    "    print(f\" Saved: {lang}_dev_predicted.csv\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# FINAL F1 SCORES\n",
    "# ---------------------------------------\n",
    "f1_df = pd.DataFrame(f1_results)\n",
    "print(\"\\n FINAL F1 SCORES:\")\n",
    "print(f1_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00492df964e049bab067d018ebd56adc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01ac45f67ed4402198010ab10100f406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "073e95e848914f7c9ceaabe00cc41128": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be90b835f97c4e23a4effb15e4a0083b",
       "IPY_MODEL_d649e316c39b4c828f1b00a6473832df",
       "IPY_MODEL_ca0c868ed4ef4029b08240b1b2823269"
      ],
      "layout": "IPY_MODEL_7f08472ccf334c6688dacaf94c48accf"
     }
    },
    "1614185f75c741e8b542653a00df8918": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b78b468dbbf4d8387c39a12202851f5",
       "IPY_MODEL_bf10726c8110417eb1ff3dbc475b46c8",
       "IPY_MODEL_add844643ddb4474a99f801ea983db59"
      ],
      "layout": "IPY_MODEL_a5c011c3b13d41d1984d7b21e6b7241e"
     }
    },
    "1bbea62722434cb893a1ee1c6c1fce14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "203c8be43bfb4a60b9cdb35c5d6db417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "22e2a6eb477a48c48d3d5db49c5b56eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23d91a6e4e354c80b2df74e671f54bf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "240ceb679ef5488384efa43d0282106d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2988af255f4b47c58ed8f252ee142881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a5cd468d01d4d80a655d8a107017bad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f10d7193f5741ae99f5f27b294c099e",
      "max": 579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_203c8be43bfb4a60b9cdb35c5d6db417",
      "value": 579
     }
    },
    "3f10d7193f5741ae99f5f27b294c099e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f38c41b8de54bc1a157d5e2426d916b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "420e28b100124dcfb28ddd6b92726835": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51472691a75f48f6a6c21a35f1f22cbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52e8370fd65a47eabead28a3eb7ad95e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23d91a6e4e354c80b2df74e671f54bf8",
      "max": 1332766994,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_240ceb679ef5488384efa43d0282106d",
      "value": 1332766994
     }
    },
    "54910b8122f44834baea2a677f41112c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "559825d487bc45768a096437b76ad3b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d734f33ecace48b581410fca9f10ee26",
       "IPY_MODEL_e77cdc8a84d741f2ac639dd87eb71f83",
       "IPY_MODEL_6fd9a522c6b7475d9ec91d2f3fec461b"
      ],
      "layout": "IPY_MODEL_6fc2d5f1fa674a0cbad03f3f073a2207"
     }
    },
    "5dc3ed1e0a7f472093683bc36ac9b770": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68aaefc2ed1646eebad344961042cf7c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a0306b070db400795d6543198f6800b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a454aae3f39b4a7fa9c1f072d5780827",
      "placeholder": "​",
      "style": "IPY_MODEL_9afe2c3474f24c0db4b6cd85cfe78dd9",
      "value": " 579/579 [00:00&lt;00:00, 78.3kB/s]"
     }
    },
    "6c2afd4186814e03bd079e2fd586b317": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fc2d5f1fa674a0cbad03f3f073a2207": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fd9a522c6b7475d9ec91d2f3fec461b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cd756f537534507a725effa96fa24c5",
      "placeholder": "​",
      "style": "IPY_MODEL_eff2605ef0f74f88ad15c723e32b3c4c",
      "value": " 1.33G/1.33G [00:01&lt;00:00, 974MB/s]"
     }
    },
    "757b334521024cf9b3aa3da809011259": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b529a3b571964df1b863be72c423b3a0",
       "IPY_MODEL_3a5cd468d01d4d80a655d8a107017bad",
       "IPY_MODEL_6a0306b070db400795d6543198f6800b"
      ],
      "layout": "IPY_MODEL_00492df964e049bab067d018ebd56adc"
     }
    },
    "773846333dcd4c4291dfafcdbc031ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68aaefc2ed1646eebad344961042cf7c",
      "placeholder": "​",
      "style": "IPY_MODEL_1bbea62722434cb893a1ee1c6c1fce14",
      "value": " 1.33G/1.33G [00:02&lt;00:00, 601MB/s]"
     }
    },
    "7b78b468dbbf4d8387c39a12202851f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cf87eadefca4dae804c838800230e85",
      "placeholder": "​",
      "style": "IPY_MODEL_9a749877cfb94eb8bfc51b6fd54fa349",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "7cd756f537534507a725effa96fa24c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf87eadefca4dae804c838800230e85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f08472ccf334c6688dacaf94c48accf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b6e7992d5984d4c945f2fa8a2ff95bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93d738a4fd5641408b37eb624c18504c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a749877cfb94eb8bfc51b6fd54fa349": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9afe2c3474f24c0db4b6cd85cfe78dd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b9377807a8b47f8a5b8ab40ac3c648d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a454aae3f39b4a7fa9c1f072d5780827": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5c011c3b13d41d1984d7b21e6b7241e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "add844643ddb4474a99f801ea983db59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc7e31e7c47f4f21b31a5fb677e50928",
      "placeholder": "​",
      "style": "IPY_MODEL_5dc3ed1e0a7f472093683bc36ac9b770",
      "value": " 52.0/52.0 [00:00&lt;00:00, 6.73kB/s]"
     }
    },
    "b1cc8a283eaf4bfab59154d84a99b514": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b529a3b571964df1b863be72c423b3a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1cc8a283eaf4bfab59154d84a99b514",
      "placeholder": "​",
      "style": "IPY_MODEL_8b6e7992d5984d4c945f2fa8a2ff95bc",
      "value": "config.json: 100%"
     }
    },
    "be6c00d7c6d045af889be8e18843a7c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be90b835f97c4e23a4effb15e4a0083b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22e2a6eb477a48c48d3d5db49c5b56eb",
      "placeholder": "​",
      "style": "IPY_MODEL_9b9377807a8b47f8a5b8ab40ac3c648d",
      "value": "spm.model: 100%"
     }
    },
    "bf10726c8110417eb1ff3dbc475b46c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c19baa8401044204a6a09519e3124541",
      "max": 52,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51472691a75f48f6a6c21a35f1f22cbc",
      "value": 52
     }
    },
    "c19baa8401044204a6a09519e3124541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca0c868ed4ef4029b08240b1b2823269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3c93164438648718aa9ac54e3e12ed6",
      "placeholder": "​",
      "style": "IPY_MODEL_54910b8122f44834baea2a677f41112c",
      "value": " 4.31M/4.31M [00:00&lt;00:00, 6.78MB/s]"
     }
    },
    "cc7e31e7c47f4f21b31a5fb677e50928": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf87da7a1938406d9a874b49ee974d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1fef065589f4476b6dc4fcc4b841ec5",
       "IPY_MODEL_52e8370fd65a47eabead28a3eb7ad95e",
       "IPY_MODEL_773846333dcd4c4291dfafcdbc031ec1"
      ],
      "layout": "IPY_MODEL_01ac45f67ed4402198010ab10100f406"
     }
    },
    "d649e316c39b4c828f1b00a6473832df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfb1f6e01c9d4d9a966a8f4cebfbed2a",
      "max": 4305025,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6843b1189fd41bfa05ebc0732275f6c",
      "value": 4305025
     }
    },
    "d6843b1189fd41bfa05ebc0732275f6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d734f33ecace48b581410fca9f10ee26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93d738a4fd5641408b37eb624c18504c",
      "placeholder": "​",
      "style": "IPY_MODEL_be6c00d7c6d045af889be8e18843a7c7",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "dfb1f6e01c9d4d9a966a8f4cebfbed2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3c93164438648718aa9ac54e3e12ed6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e77cdc8a84d741f2ac639dd87eb71f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c2afd4186814e03bd079e2fd586b317",
      "max": 1332809049,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2988af255f4b47c58ed8f252ee142881",
      "value": 1332809049
     }
    },
    "eff2605ef0f74f88ad15c723e32b3c4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1fef065589f4476b6dc4fcc4b841ec5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_420e28b100124dcfb28ddd6b92726835",
      "placeholder": "​",
      "style": "IPY_MODEL_3f38c41b8de54bc1a157d5e2426d916b",
      "value": "model.safetensors: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
